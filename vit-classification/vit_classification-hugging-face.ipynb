{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-02 13:34:28.385633: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detectron2 not imported\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import albumentations as albu\n",
    "import json\n",
    "import cv2\n",
    "from datetime import datetime\n",
    "\n",
    "import sys\n",
    "sys.path.append('../preprocess/data_loader')\n",
    "import matplotlib.pyplot as plt\n",
    "from data_loader import DataLoader\n",
    "import torch\n",
    "from datasets import Dataset, DatasetDict, Features, Value, Image, Sequence, ClassLabel\n",
    "from PIL import ImageDraw\n",
    "from PIL import Image as ImagePil\n",
    "from transformers import AutoModelForImageClassification\n",
    "from transformers import AutoImageProcessor\n",
    "from transformers import TrainingArguments, Trainer, DefaultDataCollator\n",
    "\n",
    "# For evaluate\n",
    "from torchvision.transforms import RandomResizedCrop, Compose, Normalize, ToTensor, RandomAffine\n",
    "from transformers import pipeline\n",
    "import evaluate\n",
    "from tqdm import tqdm\n",
    "import torchvision\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset generator (/tf/code/vit-classification/dataset_class_cache/generator/default-cb1ec17d9c7400e5/0.0.0)\n"
     ]
    }
   ],
   "source": [
    "#CBIS = \"/workspace/data/Mammographies/CBIS-DDSM\"\n",
    "#MIAS = \"/workspace/data/Mammographies/MIAS\"\n",
    "#INBREAST = \"/workspace/data/Mammographies/INBreast\"\n",
    "\n",
    "#loader = DataLoader(INBREAST, MIAS, CBIS)\n",
    "loader = DataLoader()\n",
    "\n",
    "features = Features({\n",
    "    'image': Image(decode=True, id=None),\n",
    "    'label': ClassLabel(names=[\"B\",\"M\"], id=None)\n",
    "})\n",
    "\n",
    "\n",
    "dataset = Dataset.from_generator(loader.classification_generator(target_library=\"hugging_face\",\n",
    "                                                                 output_size=400),\n",
    "                                 features=features,\n",
    "                                 cache_dir=\"./dataset_class_cache\",\n",
    "                                 )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'image': <PIL.PngImagePlugin.PngImageFile image mode=L size=400x400>,\n",
       " 'label': 0}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset=dataset.shuffle()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['image', 'label'],\n",
       "        num_rows: 7614\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['image', 'label'],\n",
       "        num_rows: 1632\n",
       "    })\n",
       "    valid: Dataset({\n",
       "        features: ['image', 'label'],\n",
       "        num_rows: 1632\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 90% train, 10% test + validation\n",
    "train_testvalid = dataset.train_test_split(test_size=0.3)\n",
    "# Split the 10% test + valid in half test, half valid\n",
    "test_valid = train_testvalid['test'].train_test_split(test_size=0.5)\n",
    "# gather everyone if you want to have a single DatasetDict\n",
    "dataset = DatasetDict({\n",
    "    'train': train_testvalid['train'],\n",
    "    'test': test_valid['test'],\n",
    "    'valid': test_valid['train']})\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'image': Image(decode=True, id=None),\n",
       " 'label': ClassLabel(names=['B', 'M'], id=None)}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[\"train\"].features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<PIL.PngImagePlugin.PngImageFile image mode=L size=400x400>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[\"train\"][0][\"image\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('M', 1)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = dataset[\"train\"].features[\"label\"].names\n",
    "label2id, id2label = dict(), dict()\n",
    "for i, label in enumerate(labels):\n",
    "    label2id[label] = i\n",
    "    id2label[i] = label\n",
    "    \n",
    "id2label[dataset[\"train\"][0][\"label\"]], dataset[\"train\"][0][\"label\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = \"google/vit-base-patch16-224-in21k\"\n",
    "image_processor = AutoImageProcessor.from_pretrained(checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalize = Normalize(mean=image_processor.image_mean, std=image_processor.image_std)\n",
    "size = (\n",
    "    image_processor.size[\"shortest_edge\"]\n",
    "    if \"shortest_edge\" in image_processor.size\n",
    "    else (image_processor.size[\"height\"], image_processor.size[\"width\"])\n",
    ")\n",
    "_transforms = Compose([RandomResizedCrop(size),\n",
    "                       RandomAffine(degrees=90,translate=(0.25,0.25),scale=(0.8,1)),\n",
    "                       ToTensor(),\n",
    "                       normalize])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transforms(examples):\n",
    "    examples[\"pixel_values\"] = [_transforms(img.convert(\"RGB\")) for img in examples[\"image\"]]\n",
    "    del examples[\"image\"]\n",
    "    return examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = dataset.with_transform(transforms)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Search Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_collator = DefaultDataCollator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = evaluate.load(\"accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(eval_pred):\n",
    "    predictions, labels = eval_pred\n",
    "    predictions = np.argmax(predictions, axis=1)\n",
    "    return accuracy.compute(predictions=predictions, references=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optuna_hp_space(trial):\n",
    "    return {\n",
    "        \"learning_rate\": trial.suggest_float(\"learning_rate\", 1e-6, 1e-4, log=True),\n",
    "        \"weight_decay\": trial.suggest_float(\"weight_decay\", 1e-6, 1e-4, log=True),\n",
    "        \"gradient_accumulation_steps\": trial.suggest_categorical(\"gradient_accumulation_steps\",\n",
    "                                                                [1, 2, 4, 8]),\n",
    "        \"per_device_train_batch_size\": trial.suggest_categorical(\"per_device_train_batch_size\",\n",
    "                                                                [1,2,4,8]),\n",
    "        \"warmup_ratio\": trial.suggest_float(\"warmup_ratio\",0.1,0.5,step=0.05),\n",
    "    }\n",
    "\n",
    "def model_init(trial):     \n",
    "    return AutoModelForImageClassification.from_pretrained(\n",
    "        checkpoint,\n",
    "        num_labels=len(labels),\n",
    "        id2label=id2label,\n",
    "        label2id=label2id,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at google/vit-base-patch16-224-in21k were not used when initializing ViTForImageClassification: ['pooler.dense.weight', 'pooler.dense.bias']\n",
      "- This IS expected if you are initializing ViTForImageClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ViTForImageClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of ViTForImageClassification were not initialized from the model checkpoint at google/vit-base-patch16-224-in21k and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of the model checkpoint at google/vit-base-patch16-224-in21k were not used when initializing ViTForImageClassification: ['pooler.dense.weight', 'pooler.dense.bias']\n",
      "- This IS expected if you are initializing ViTForImageClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ViTForImageClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of ViTForImageClassification were not initialized from the model checkpoint at google/vit-base-patch16-224-in21k and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/optimization.py:407: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='14' max='14' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [14/14 00:08, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.604200</td>\n",
       "      <td>0.593433</td>\n",
       "      <td>0.710280</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-27 23:24:09,472]\u001b[0m A new study created in memory with name: no-name-70754094-48e6-4c19-a27e-50d9f9d7c9f8\u001b[0m\n",
      "Some weights of the model checkpoint at google/vit-base-patch16-224-in21k were not used when initializing ViTForImageClassification: ['pooler.dense.weight', 'pooler.dense.bias']\n",
      "- This IS expected if you are initializing ViTForImageClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ViTForImageClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of ViTForImageClassification were not initialized from the model checkpoint at google/vit-base-patch16-224-in21k and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/optimization.py:407: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='54' max='54' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [54/54 00:11, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.736000</td>\n",
       "      <td>0.613500</td>\n",
       "      <td>0.710280</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-27 23:24:21,624]\u001b[0m Trial 0 finished with value: 0.7102803738317757 and parameters: {'learning_rate': 7.670644609610572e-06, 'weight_decay': 4.0329670011139824e-05, 'gradient_accumulation_steps': 2, 'per_device_train_batch_size': 1, 'warmup_ratio': 0.4}. Best is trial 0 with value: 0.7102803738317757.\u001b[0m\n",
      "Some weights of the model checkpoint at google/vit-base-patch16-224-in21k were not used when initializing ViTForImageClassification: ['pooler.dense.weight', 'pooler.dense.bias']\n",
      "- This IS expected if you are initializing ViTForImageClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ViTForImageClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of ViTForImageClassification were not initialized from the model checkpoint at google/vit-base-patch16-224-in21k and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/optimization.py:407: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1/1 00:03, Epoch 0/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.694625</td>\n",
       "      <td>0.457944</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-27 23:24:28,324]\u001b[0m Trial 1 finished with value: 0.45794392523364486 and parameters: {'learning_rate': 1.540066750669641e-06, 'weight_decay': 3.0830089082018345e-06, 'gradient_accumulation_steps': 8, 'per_device_train_batch_size': 8, 'warmup_ratio': 0.25}. Best is trial 0 with value: 0.7102803738317757.\u001b[0m\n",
      "Some weights of the model checkpoint at google/vit-base-patch16-224-in21k were not used when initializing ViTForImageClassification: ['pooler.dense.weight', 'pooler.dense.bias']\n",
      "- This IS expected if you are initializing ViTForImageClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ViTForImageClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of ViTForImageClassification were not initialized from the model checkpoint at google/vit-base-patch16-224-in21k and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/optimization.py:407: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6' max='6' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [6/6 00:07, Epoch 0/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.613305</td>\n",
       "      <td>0.710280</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-27 23:24:37,361]\u001b[0m Trial 2 finished with value: 0.7102803738317757 and parameters: {'learning_rate': 3.0706147699624944e-05, 'weight_decay': 1.628908403674015e-05, 'gradient_accumulation_steps': 4, 'per_device_train_batch_size': 4, 'warmup_ratio': 0.4}. Best is trial 0 with value: 0.7102803738317757.\u001b[0m\n",
      "Some weights of the model checkpoint at google/vit-base-patch16-224-in21k were not used when initializing ViTForImageClassification: ['pooler.dense.weight', 'pooler.dense.bias']\n",
      "- This IS expected if you are initializing ViTForImageClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ViTForImageClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of ViTForImageClassification were not initialized from the model checkpoint at google/vit-base-patch16-224-in21k and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/optimization.py:407: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='14' max='14' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [14/14 00:07, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.691600</td>\n",
       "      <td>0.680666</td>\n",
       "      <td>0.672897</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-27 23:24:46,358]\u001b[0m Trial 3 finished with value: 0.6728971962616822 and parameters: {'learning_rate': 1.2787726716448358e-06, 'weight_decay': 7.367487739472977e-05, 'gradient_accumulation_steps': 1, 'per_device_train_batch_size': 8, 'warmup_ratio': 0.4}. Best is trial 0 with value: 0.7102803738317757.\u001b[0m\n",
      "Some weights of the model checkpoint at google/vit-base-patch16-224-in21k were not used when initializing ViTForImageClassification: ['pooler.dense.weight', 'pooler.dense.bias']\n",
      "- This IS expected if you are initializing ViTForImageClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ViTForImageClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of ViTForImageClassification were not initialized from the model checkpoint at google/vit-base-patch16-224-in21k and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/optimization.py:407: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='54' max='54' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [54/54 00:10, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.956800</td>\n",
       "      <td>0.595040</td>\n",
       "      <td>0.710280</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-27 23:24:57,379]\u001b[0m Trial 4 finished with value: 0.7102803738317757 and parameters: {'learning_rate': 4.802754566801389e-05, 'weight_decay': 6.066110175546886e-06, 'gradient_accumulation_steps': 1, 'per_device_train_batch_size': 2, 'warmup_ratio': 0.2}. Best is trial 0 with value: 0.7102803738317757.\u001b[0m\n",
      "Some weights of the model checkpoint at google/vit-base-patch16-224-in21k were not used when initializing ViTForImageClassification: ['pooler.dense.weight', 'pooler.dense.bias']\n",
      "- This IS expected if you are initializing ViTForImageClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ViTForImageClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of ViTForImageClassification were not initialized from the model checkpoint at google/vit-base-patch16-224-in21k and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/optimization.py:407: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3' max='3' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3/3 00:05, Epoch 0/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.651062</td>\n",
       "      <td>0.710280</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-27 23:25:05,559]\u001b[0m Trial 5 finished with value: 0.7102803738317757 and parameters: {'learning_rate': 1.958922933289827e-05, 'weight_decay': 1.8689309417818546e-05, 'gradient_accumulation_steps': 4, 'per_device_train_batch_size': 8, 'warmup_ratio': 0.2}. Best is trial 0 with value: 0.7102803738317757.\u001b[0m\n",
      "Some weights of the model checkpoint at google/vit-base-patch16-224-in21k were not used when initializing ViTForImageClassification: ['pooler.dense.weight', 'pooler.dense.bias']\n",
      "- This IS expected if you are initializing ViTForImageClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ViTForImageClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of ViTForImageClassification were not initialized from the model checkpoint at google/vit-base-patch16-224-in21k and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/optimization.py:407: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='13' max='13' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [13/13 00:08, Epoch 0/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.691300</td>\n",
       "      <td>0.678780</td>\n",
       "      <td>0.682243</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-27 23:25:15,533]\u001b[0m Trial 6 finished with value: 0.6822429906542056 and parameters: {'learning_rate': 1.3726493662318098e-06, 'weight_decay': 9.762798200884735e-06, 'gradient_accumulation_steps': 4, 'per_device_train_batch_size': 2, 'warmup_ratio': 0.4}. Best is trial 0 with value: 0.7102803738317757.\u001b[0m\n",
      "Some weights of the model checkpoint at google/vit-base-patch16-224-in21k were not used when initializing ViTForImageClassification: ['pooler.dense.weight', 'pooler.dense.bias']\n",
      "- This IS expected if you are initializing ViTForImageClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ViTForImageClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of ViTForImageClassification were not initialized from the model checkpoint at google/vit-base-patch16-224-in21k and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/optimization.py:407: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3' max='3' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3/3 00:06, Epoch 0/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.605691</td>\n",
       "      <td>0.710280</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-27 23:25:23,701]\u001b[0m Trial 7 finished with value: 0.7102803738317757 and parameters: {'learning_rate': 6.296124640503161e-05, 'weight_decay': 1.803363616601628e-05, 'gradient_accumulation_steps': 4, 'per_device_train_batch_size': 8, 'warmup_ratio': 0.15000000000000002}. Best is trial 0 with value: 0.7102803738317757.\u001b[0m\n",
      "Some weights of the model checkpoint at google/vit-base-patch16-224-in21k were not used when initializing ViTForImageClassification: ['pooler.dense.weight', 'pooler.dense.bias']\n",
      "- This IS expected if you are initializing ViTForImageClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ViTForImageClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of ViTForImageClassification were not initialized from the model checkpoint at google/vit-base-patch16-224-in21k and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/optimization.py:407: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='27' max='27' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [27/27 00:10, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.574900</td>\n",
       "      <td>0.596581</td>\n",
       "      <td>0.710280</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-27 23:25:34,972]\u001b[0m Trial 8 finished with value: 0.7102803738317757 and parameters: {'learning_rate': 2.0297069941979907e-05, 'weight_decay': 2.4364592879473007e-05, 'gradient_accumulation_steps': 4, 'per_device_train_batch_size': 1, 'warmup_ratio': 0.45000000000000007}. Best is trial 0 with value: 0.7102803738317757.\u001b[0m\n",
      "Some weights of the model checkpoint at google/vit-base-patch16-224-in21k were not used when initializing ViTForImageClassification: ['pooler.dense.weight', 'pooler.dense.bias']\n",
      "- This IS expected if you are initializing ViTForImageClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ViTForImageClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of ViTForImageClassification were not initialized from the model checkpoint at google/vit-base-patch16-224-in21k and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/optimization.py:407: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='7' max='7' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [7/7 00:07, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.638683</td>\n",
       "      <td>0.719626</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-27 23:25:43,835]\u001b[0m Trial 9 finished with value: 0.719626168224299 and parameters: {'learning_rate': 1.3987046711934422e-05, 'weight_decay': 8.352297244089028e-06, 'gradient_accumulation_steps': 2, 'per_device_train_batch_size': 8, 'warmup_ratio': 0.30000000000000004}. Best is trial 9 with value: 0.719626168224299.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=\"hyper_params\",\n",
    "    remove_unused_columns=False,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    per_device_eval_batch_size=8,\n",
    "    num_train_epochs=1,\n",
    "    logging_steps=10,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"accuracy\",\n",
    "    push_to_hub=False,\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=None,\n",
    "    args=training_args,\n",
    "    data_collator=data_collator,\n",
    "    train_dataset=ds[\"train\"],\n",
    "    eval_dataset=ds[\"valid\"],\n",
    "    tokenizer=image_processor,\n",
    "    model_init=model_init,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "trainer.train()\n",
    "\n",
    "best_trial = trainer.hyperparameter_search(\n",
    "    direction=\"maximize\", #default metric is loss\n",
    "    backend=\"optuna\",\n",
    "    hp_space=optuna_hp_space,\n",
    "    n_trials=10,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BestRun(run_id='9', objective=0.719626168224299, hyperparameters={'learning_rate': 1.3987046711934422e-05, 'weight_decay': 8.352297244089028e-06, 'gradient_accumulation_steps': 2, 'per_device_train_batch_size': 8, 'warmup_ratio': 0.30000000000000004}, run_summary=None)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"Parameters:\n",
    "        run_id (:obj:`str`):\n",
    "            The id of the best run (if models were saved, the corresponding checkpoint will be in the folder ending\n",
    "            with run-{run_id}).\n",
    "        objective (:obj:`float`):\n",
    "            The objective that was obtained for this run.\n",
    "        hyperparameters (:obj:`Dict[str, Any]`):\n",
    "            The hyperparameters picked to get this run.\n",
    "\"\"\"\n",
    "best_trial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at google/vit-base-patch16-224-in21k were not used when initializing ViTForImageClassification: ['pooler.dense.weight', 'pooler.dense.bias']\n",
      "- This IS expected if you are initializing ViTForImageClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ViTForImageClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of ViTForImageClassification were not initialized from the model checkpoint at google/vit-base-patch16-224-in21k and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/optimization.py:407: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='70' max='70' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [70/70 01:18, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.699007</td>\n",
       "      <td>0.514019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.701400</td>\n",
       "      <td>0.658022</td>\n",
       "      <td>0.700935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.662600</td>\n",
       "      <td>0.623147</td>\n",
       "      <td>0.719626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.662600</td>\n",
       "      <td>0.599767</td>\n",
       "      <td>0.710280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.645200</td>\n",
       "      <td>0.589150</td>\n",
       "      <td>0.719626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.596700</td>\n",
       "      <td>0.583369</td>\n",
       "      <td>0.719626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.596700</td>\n",
       "      <td>0.582168</td>\n",
       "      <td>0.710280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.597500</td>\n",
       "      <td>0.582109</td>\n",
       "      <td>0.719626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.590500</td>\n",
       "      <td>0.572789</td>\n",
       "      <td>0.747664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.614200</td>\n",
       "      <td>0.570119</td>\n",
       "      <td>0.728972</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=70, training_loss=0.6297310761043003, metrics={'train_runtime': 79.6319, 'train_samples_per_second': 13.562, 'train_steps_per_second': 0.879, 'total_flos': 8.369134878375936e+16, 'train_loss': 0.6297310761043003, 'epoch': 10.0})"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = AutoModelForImageClassification.from_pretrained(\n",
    "    checkpoint,\n",
    "    num_labels=len(labels),\n",
    "    id2label=id2label,\n",
    "    label2id=label2id,\n",
    ")\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=f'/workspace/test_vit_class_{checkpoint.replace(\"/\",\"_\")}_{datetime.now().strftime(\"%d%m%Y_%H%M%S\")}',\n",
    "    num_train_epochs=10,\n",
    "    learning_rate=best_trial.hyperparameters[\"learning_rate\"],\n",
    "    weight_decay=best_trial.hyperparameters[\"weight_decay\"],\n",
    "    warmup_ratio=best_trial.hyperparameters[\"warmup_ratio\"],\n",
    "    gradient_accumulation_steps=best_trial.hyperparameters[\"gradient_accumulation_steps\"],\n",
    "    per_device_train_batch_size=best_trial.hyperparameters[\"per_device_train_batch_size\"],\n",
    "    per_device_eval_batch_size=8,\n",
    "    metric_for_best_model=\"accuracy\",\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    load_best_model_at_end=True,\n",
    "    remove_unused_columns=False,\n",
    "    logging_steps=10,\n",
    "    push_to_hub=False,\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    data_collator=data_collator,\n",
    "    train_dataset=ds[\"train\"],\n",
    "    eval_dataset=ds[\"valid\"],\n",
    "    tokenizer=image_processor,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_name=f'./vit_class_{checkpoint.replace(\"/\",\"_\")}_{datetime.now().strftime(\"%d%m%Y_%H%M%S\")}'\n",
    "model.save_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = albu.Compose([\n",
    "                albu.CLAHE(clip_limit=(1, 10), p=1),\n",
    "            ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'B'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if 'model_name' not in globals():\n",
    "    model = AutoModelForImageClassification.from_pretrained(\n",
    "        \"./vit_class_google_vit-base-patch16-224-in21k_27052023_232704\",\n",
    "        num_labels=len(labels),\n",
    "        id2label=id2label,\n",
    "        label2id=label2id,\n",
    "    )\n",
    "\n",
    "model_cpu = model.to(\"cpu\")\n",
    "\n",
    "test_sample = dataset[\"test\"][5][\"image\"]\n",
    "\n",
    "processed_sample = transform(image=np.array(test_sample.convert(\"RGB\")))\n",
    "\n",
    "image = ImagePil.fromarray(processed_sample[\"image\"])\n",
    "\n",
    "inputs = image_processor(images=image, return_tensors=\"pt\")\n",
    "with torch.no_grad():\n",
    "    logits = model_cpu(**inputs).logits\n",
    "predicted_label = logits.argmax(-1).item()\n",
    "id2label[predicted_label]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'score': 0.6404788494110107, 'label': 'B'},\n",
       " {'score': 0.35952118039131165, 'label': 'M'}]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_cpu = model.to(\"cpu\")\n",
    "\n",
    "test_sample = dataset[\"test\"][5][\"image\"]\n",
    "\n",
    "processed_sample = transform(image=np.array(test_sample.convert(\"RGB\")))\n",
    "\n",
    "image = ImagePil.fromarray(processed_sample[\"image\"])\n",
    "\n",
    "classifier = pipeline(\"image-classification\", model=model, image_processor=image_processor)\n",
    "results=classifier(image)\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'score': 0.6404788494110107, 'label': 'B'}"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(results, key=lambda x: x[\"score\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = trainer.evaluate(ds['test'])\n",
    "trainer.log_metrics(\"eval\", metrics)\n",
    "trainer.save_metrics(\"eval\", metrics)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
