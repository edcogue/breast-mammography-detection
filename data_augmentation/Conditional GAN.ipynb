{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b381f564",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-05 21:54:40.182754: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "from IPython import display\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Dense, Flatten, Conv2D, BatchNormalization\n",
    "from tensorflow.keras import Model\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "44e530e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "num_channels = 1\n",
    "num_classes = 10\n",
    "image_size = 28\n",
    "latent_dim = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a9efcc84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of training images: (70000, 28, 28, 1)\n",
      "Shape of training labels: (70000, 10)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-05 21:54:44.915410: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-06-05 21:54:44.919418: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-06-05 21:54:44.919591: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-06-05 21:54:44.920685: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-06-05 21:54:44.920843: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-06-05 21:54:44.920985: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-06-05 21:54:45.536856: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-06-05 21:54:45.537058: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-06-05 21:54:45.537232: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-06-05 21:54:45.537401: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 4497 MB memory:  -> device: 0, name: NVIDIA GeForce GTX 1660 Ti, pci bus id: 0000:01:00.0, compute capability: 7.5\n"
     ]
    }
   ],
   "source": [
    "# We'll use all the available examples from both the training and test\n",
    "# sets.\n",
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
    "all_digits = np.concatenate([x_train, x_test])\n",
    "all_labels = np.concatenate([y_train, y_test])\n",
    "\n",
    "# Scale the pixel values to [0, 1] range, add a channel dimension to\n",
    "# the images, and one-hot encode the labels.\n",
    "all_digits = all_digits.astype(\"float32\") / 255.0\n",
    "all_digits = np.reshape(all_digits, (-1, 28, 28, 1))\n",
    "all_labels = tf.keras.utils.to_categorical(all_labels, 10)\n",
    "\n",
    "# Create tf.data.Dataset.\n",
    "dataset = tf.data.Dataset.from_tensor_slices((all_digits, all_labels))\n",
    "dataset = dataset.shuffle(buffer_size=1024).batch(batch_size)\n",
    "\n",
    "print(f\"Shape of training images: {all_digits.shape}\")\n",
    "print(f\"Shape of training labels: {all_labels.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e7286653",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "138 11\n"
     ]
    }
   ],
   "source": [
    "generator_in_channels = latent_dim + num_classes\n",
    "discriminator_in_channels = num_channels + num_classes\n",
    "print(generator_in_channels, discriminator_in_channels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "37b51697",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the discriminator.\n",
    "discriminator = tf.keras.Sequential(\n",
    "    [\n",
    "        tf.keras.layers.InputLayer((28, 28, discriminator_in_channels)),\n",
    "        tf.keras.layers.Conv2D(64, (3, 3), strides=(2, 2), padding=\"same\"),\n",
    "        tf.keras.layers.LeakyReLU(alpha=0.2),\n",
    "        tf.keras.layers.Conv2D(128, (3, 3), strides=(2, 2), padding=\"same\"),\n",
    "        tf.keras.layers.LeakyReLU(alpha=0.2),\n",
    "        tf.keras.layers.GlobalMaxPooling2D(),\n",
    "        tf.keras.layers.Dense(1),\n",
    "    ],\n",
    "    name=\"discriminator\",\n",
    ")\n",
    "\n",
    "# Create the generator.\n",
    "generator = tf.keras.Sequential(\n",
    "    [\n",
    "        tf.keras.layers.InputLayer((generator_in_channels,)),\n",
    "        # We want to generate 128 + num_classes coefficients to reshape into a\n",
    "        # 7x7x(128 + num_classes) map.\n",
    "        tf.keras.layers.Dense(7 * 7 * generator_in_channels),\n",
    "        tf.keras.layers.LeakyReLU(alpha=0.2),\n",
    "        tf.keras.layers.Reshape((7, 7, generator_in_channels)),\n",
    "        tf.keras.layers.Conv2DTranspose(128, (4, 4), strides=(2, 2), padding=\"same\"),\n",
    "        tf.keras.layers.LeakyReLU(alpha=0.2),\n",
    "        tf.keras.layers.Conv2DTranspose(128, (4, 4), strides=(2, 2), padding=\"same\"),\n",
    "        tf.keras.layers.LeakyReLU(alpha=0.2),\n",
    "        tf.keras.layers.Conv2D(1, (7, 7), padding=\"same\", activation=\"sigmoid\"),\n",
    "    ],\n",
    "    name=\"generator\",\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1a04f506",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConditionalGAN(tf.keras.Model):\n",
    "    def __init__(self, discriminator, generator, latent_dim):\n",
    "        super().__init__()\n",
    "        self.discriminator = discriminator\n",
    "        self.generator = generator\n",
    "        self.latent_dim = latent_dim\n",
    "        self.gen_loss_tracker = tf.keras.metrics.Mean(name=\"generator_loss\")\n",
    "        self.disc_loss_tracker = tf.keras.metrics.Mean(name=\"discriminator_loss\")\n",
    "\n",
    "    @property\n",
    "    def metrics(self):\n",
    "        return [self.gen_loss_tracker, self.disc_loss_tracker]\n",
    "\n",
    "    def compile(self, d_optimizer, g_optimizer, loss_fn):\n",
    "        super().compile()\n",
    "        self.d_optimizer = d_optimizer\n",
    "        self.g_optimizer = g_optimizer\n",
    "        self.loss_fn = loss_fn\n",
    "\n",
    "    def train_step(self, data):\n",
    "        # Unpack the data.\n",
    "        real_images, one_hot_labels = data\n",
    "\n",
    "        # Add dummy dimensions to the labels so that they can be concatenated with\n",
    "        # the images. This is for the discriminator.\n",
    "        image_one_hot_labels = one_hot_labels[:, :, None, None]\n",
    "        image_one_hot_labels = tf.repeat(\n",
    "            image_one_hot_labels, repeats=[image_size * image_size]\n",
    "        )\n",
    "        image_one_hot_labels = tf.reshape(\n",
    "            image_one_hot_labels, (-1, image_size, image_size, num_classes)\n",
    "        )\n",
    "\n",
    "        # Sample random points in the latent space and concatenate the labels.\n",
    "        # This is for the generator.\n",
    "        batch_size = tf.shape(real_images)[0]\n",
    "        random_latent_vectors = tf.random.normal(shape=(batch_size, self.latent_dim))\n",
    "        random_vector_labels = tf.concat(\n",
    "            [random_latent_vectors, one_hot_labels], axis=1\n",
    "        )\n",
    "\n",
    "        # Decode the noise (guided by labels) to fake images.\n",
    "        generated_images = self.generator(random_vector_labels)\n",
    "\n",
    "        # Combine them with real images. Note that we are concatenating the labels\n",
    "        # with these images here.\n",
    "        fake_image_and_labels = tf.concat([generated_images, image_one_hot_labels], -1)\n",
    "        real_image_and_labels = tf.concat([real_images, image_one_hot_labels], -1)\n",
    "        combined_images = tf.concat(\n",
    "            [fake_image_and_labels, real_image_and_labels], axis=0\n",
    "        )\n",
    "\n",
    "        # Assemble labels discriminating real from fake images.\n",
    "        labels = tf.concat(\n",
    "            [tf.ones((batch_size, 1)), tf.zeros((batch_size, 1))], axis=0\n",
    "        )\n",
    "\n",
    "        # Train the discriminator.\n",
    "        with tf.GradientTape() as tape:\n",
    "            predictions = self.discriminator(combined_images)\n",
    "            d_loss = self.loss_fn(labels, predictions)\n",
    "        grads = tape.gradient(d_loss, self.discriminator.trainable_weights)\n",
    "        self.d_optimizer.apply_gradients(\n",
    "            zip(grads, self.discriminator.trainable_weights)\n",
    "        )\n",
    "\n",
    "        # Sample random points in the latent space.\n",
    "        random_latent_vectors = tf.random.normal(shape=(batch_size, self.latent_dim))\n",
    "        random_vector_labels = tf.concat(\n",
    "            [random_latent_vectors, one_hot_labels], axis=1\n",
    "        )\n",
    "\n",
    "        # Assemble labels that say \"all real images\".\n",
    "        misleading_labels = tf.zeros((batch_size, 1))\n",
    "\n",
    "        # Train the generator (note that we should *not* update the weights\n",
    "        # of the discriminator)!\n",
    "        with tf.GradientTape() as tape:\n",
    "            fake_images = self.generator(random_vector_labels)\n",
    "            fake_image_and_labels = tf.concat([fake_images, image_one_hot_labels], -1)\n",
    "            predictions = self.discriminator(fake_image_and_labels)\n",
    "            g_loss = self.loss_fn(misleading_labels, predictions)\n",
    "        grads = tape.gradient(g_loss, self.generator.trainable_weights)\n",
    "        self.g_optimizer.apply_gradients(zip(grads, self.generator.trainable_weights))\n",
    "\n",
    "        # Monitor loss.\n",
    "        self.gen_loss_tracker.update_state(g_loss)\n",
    "        self.disc_loss_tracker.update_state(d_loss)\n",
    "        return {\n",
    "            \"g_loss\": self.gen_loss_tracker.result(),\n",
    "            \"d_loss\": self.disc_loss_tracker.result(),\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b5ecffcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "cond_gan = ConditionalGAN(\n",
    "    discriminator=discriminator, generator=generator, latent_dim=latent_dim\n",
    ")\n",
    "cond_gan.compile(\n",
    "    d_optimizer=tf.keras.optimizers.Adam(learning_rate=0.0003),\n",
    "    g_optimizer=tf.keras.optimizers.Adam(learning_rate=0.0003),\n",
    "    loss_fn=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c96d0f2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-05 21:54:58.775758: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_1' with dtype float and shape [70000,10]\n",
      "\t [[{{node Placeholder/_1}}]]\n",
      "2023-06-05 21:54:58.776005: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_1' with dtype float and shape [70000,10]\n",
      "\t [[{{node Placeholder/_1}}]]\n",
      "2023-06-05 21:55:00.560398: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:424] Loaded cuDNN version 8600\n",
      "2023-06-05 21:55:01.664505: I tensorflow/compiler/xla/service/service.cc:169] XLA service 0x20af45d0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2023-06-05 21:55:01.664536: I tensorflow/compiler/xla/service/service.cc:177]   StreamExecutor device (0): NVIDIA GeForce GTX 1660 Ti, Compute Capability 7.5\n",
      "2023-06-05 21:55:01.668800: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2023-06-05 21:55:01.784096: I ./tensorflow/compiler/jit/device_compiler.h:180] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1094/1094 [==============================] - 34s 26ms/step - g_loss: 1.6081 - d_loss: 0.4123\n",
      "Epoch 2/20\n",
      "1094/1094 [==============================] - 28s 26ms/step - g_loss: 1.5951 - d_loss: 0.4293\n",
      "Epoch 3/20\n",
      "1094/1094 [==============================] - 28s 26ms/step - g_loss: 1.8416 - d_loss: 0.3481\n",
      "Epoch 4/20\n",
      "1094/1094 [==============================] - 28s 26ms/step - g_loss: 2.4453 - d_loss: 0.1887\n",
      "Epoch 5/20\n",
      "1094/1094 [==============================] - 28s 26ms/step - g_loss: 1.3732 - d_loss: 0.5489\n",
      "Epoch 6/20\n",
      "1094/1094 [==============================] - 29s 26ms/step - g_loss: 0.9951 - d_loss: 0.6327\n",
      "Epoch 7/20\n",
      "1094/1094 [==============================] - 29s 26ms/step - g_loss: 0.8985 - d_loss: 0.6540\n",
      "Epoch 8/20\n",
      "1094/1094 [==============================] - 28s 26ms/step - g_loss: 0.8353 - d_loss: 0.6640\n",
      "Epoch 9/20\n",
      "1094/1094 [==============================] - 28s 26ms/step - g_loss: 0.8107 - d_loss: 0.6738\n",
      "Epoch 10/20\n",
      "1094/1094 [==============================] - 28s 26ms/step - g_loss: 0.7916 - d_loss: 0.6786\n",
      "Epoch 11/20\n",
      "1094/1094 [==============================] - 28s 26ms/step - g_loss: 0.7710 - d_loss: 0.6810\n",
      "Epoch 12/20\n",
      "1094/1094 [==============================] - 29s 26ms/step - g_loss: 0.7726 - d_loss: 0.6766\n",
      "Epoch 13/20\n",
      "1094/1094 [==============================] - 29s 26ms/step - g_loss: 0.7776 - d_loss: 0.6720\n",
      "Epoch 14/20\n",
      "1094/1094 [==============================] - 29s 26ms/step - g_loss: 0.7676 - d_loss: 0.6767\n",
      "Epoch 15/20\n",
      "1094/1094 [==============================] - 29s 26ms/step - g_loss: 0.7511 - d_loss: 0.6841\n",
      "Epoch 16/20\n",
      "1094/1094 [==============================] - 29s 26ms/step - g_loss: 0.7638 - d_loss: 0.6742\n",
      "Epoch 17/20\n",
      "1094/1094 [==============================] - 29s 26ms/step - g_loss: 0.7594 - d_loss: 0.6815\n",
      "Epoch 18/20\n",
      "1094/1094 [==============================] - 29s 26ms/step - g_loss: 0.7701 - d_loss: 0.6714\n",
      "Epoch 19/20\n",
      "1094/1094 [==============================] - 29s 26ms/step - g_loss: 0.7708 - d_loss: 0.6771\n",
      "Epoch 20/20\n",
      "1094/1094 [==============================] - 29s 26ms/step - g_loss: 0.7697 - d_loss: 0.6678\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fa3a86c38b0>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cond_gan.fit(dataset, epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5fbcc835",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-05 22:11:58.387125: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,?,?,138]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-06-05 22:11:58.404758: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,?,?,128]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-06-05 22:11:58.497097: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,6762]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-06-05 22:11:58.654989: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,6762]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-06-05 22:11:58.664834: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,?,?,138]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-06-05 22:11:58.685801: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,?,?,128]\n",
      "\t [[{{node inputs}}]]\n",
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 3 of 3). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: gan_mnist/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: gan_mnist/assets\n"
     ]
    }
   ],
   "source": [
    "cond_gan.generator.save(\"gan_mnist\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0ae5073f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    }
   ],
   "source": [
    "trained_gen = tf.keras.models.load_model(\"gan_mnist\")\n",
    "trained_gen.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5e306148",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 15ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fa20c67b8b0>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# We first extract the trained generator from our Conditiona GAN.\n",
    "\n",
    "def generate_sample(label_ex):\n",
    "    interpolation_noise = tf.random.normal(shape=(1, latent_dim))\n",
    "    label = tf.keras.utils.to_categorical([label_ex], num_classes)\n",
    "    label = tf.cast(label, tf.float32)\n",
    "    noise_and_label = tf.concat([interpolation_noise, label], 1)\n",
    "    fake = trained_gen.predict(noise_and_label)\n",
    "    fake *= 255\n",
    "    return fake.astype(np.uint8)\n",
    "\n",
    "plt.imshow(generate_sample(9)[0], cmap=\"gray\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
